Nt <- Nx + Ny
fx <- Nt / Nx
fy <- Nt / Ny
Zx <- 1 - fx * params[1] * (x - params[2])
Zy <- 1 + fy * params[1] * (y - params[2])
return(-sum(log.star(Zy, 1 / Nx)) - sum(log.star(Zx, 1 / Ny)))
}
source("R/trials/trial_loader.R")
test_ <- function(trial) {
x <- trial$Score
group <- trial$Group
# map group to 1 and 0
group <- as.numeric(group == "treatment")
return(ELRT(x, group))
}
p_value_type <- "Fpvalue" # "X2pvalue" # "Fpvalue"
trial_data <- load_equal_trials()
df <- trial_data$apply_to_each(test_, as.df = TRUE)
na_count_equal <- sum(is.na(df[[p_value_type]]))
p_values <- df[[p_value_type]][!is.na(df[[p_value_type]])]
p_value_rate_equal <- sum(p_values < 0.05) / length(p_values)
trial_data <- load_longer_trials()
df <- trial_data$apply_to_each(test_, as.df = TRUE)
GetInput <- function(x) {
cont <- x[x > 0]
Npm <- length(x) - length(cont)
Nc <- length(cont)
p.hat <- Npm / length(x)
muCont <- mean(cont, na.rm = TRUE)
varCont <- var(cont, na.rm = TRUE)
alpha <- varCont / (muCont^2)
ans <- list(cont = numeric(), Npm = numeric(), Nc = numeric(),
p.hat = numeric(), theta = numeric())
ans$cont <- cont
ans$Npm <- Npm
ans$Nc <- Nc
ans$p.hat <- p.hat
ans$theta <- alpha
return(ans)
}
GetWeights <- function(fit, contX, contY) {
Lambda <- fit$estimate[1]
Mean <- fit$estimate[2]
Nx <- length(contX)
Ny <- length(contY)
Nt <- Nx + Ny
fx <- Nt / Nx
fy <- Nt / Ny
Zx <- 1 - fx * Lambda * (contX - Mean)
Zy <- 1 + fy * Lambda * (contY - Mean)
wts <- cbind(sum(c(1 / (Nx * Zx))), sum(c(1 / (Ny * Zy))))
return(wts)
}
ELRT <- function(data, group) {
Ho <- GetInput(data)
Index1 <- c(group == 1)
Group1 <- data[Index1]
Group0 <- data[!Index1]
Ha1 <- GetInput(Group1)
Ha2 <- GetInput(Group0)
BigMean <- mean(Ho$cont, na.rm = TRUE)
if (Ho$Nc == 0) {
flag <- 0
null.logl <- 0
G1.logl <- 0
G0.logl <- 0
contELRT <- 0
}
else if (Ha1$Nc == 0) {
flag <- 0
null.logl <- (Ho$Npm * log(Ho$p.hat)) + (Ho$Nc * log(1 - Ho$p.hat))
if (Ha2$Npm == 0) {
G1.logl <- (Ha1$Npm * log(Ha1$p.hat))
G0.logl <- (Ha2$Nc * log(1 - Ha2$p.hat))
} else {
G1.logl <- (Ha1$Npm * log(Ha1$p.hat))
G0.logl <- (Ha2$Npm * log(Ha2$p.hat)) + (Ha2$Nc * log(1 -
Ha2$p.hat))
}
contELRT <- 0
}
else if (Ha2$Nc == 0) {
flag <- 0
null.logl <- (Ho$Npm * log(Ho$p.hat)) + (Ho$Nc * log(1 - Ho$p.hat))
if (Ha1$Npm == 0) {
G1.logl <- (Ha1$Nc * log(1 - Ha1$p.hat))
G0.logl <- (Ha2$Npm * log(Ha2$p.hat))
} else {
G1.logl <- (Ha1$Npm * log(Ha1$p.hat)) + (Ha1$Nc * log(1 -
Ha1$p.hat))
G0.logl <- (Ha2$Npm * log(Ha2$p.hat))
}
contELRT <- 0
}
else if (Ha1$Nc == 1) {
flag <- 0
null.logl <- (Ho$Npm * log(Ho$p.hat)) + (Ho$Nc * log(1 - Ho$p.hat))
contELRT <- 0
if (Ha2$Npm == 0) {
G1.logl <- (Ha1$Npm * log(Ha1$p.hat)) + (Ha1$Nc * log(1 -
Ha1$p.hat))
G0.logl <- (Ha2$Nc * log(1 - Ha2$p.hat))
contELRT <- 0
} else {
G1.logl <- (Ha1$Npm * log(Ha1$p.hat)) + (Ha1$Nc * log(1 -
Ha1$p.hat))
G0.logl <- (Ha2$Npm * log(Ha2$p.hat)) + (Ha2$Nc * log(1 -
Ha2$p.hat))
contELRT <- 0
}
} else if (Ha2$Nc == 1) {
flag <- 0
null.logl <- (Ho$Npm * log(Ho$p.hat)) + (Ho$Nc * log(1 - Ho$p.hat))
if (Ha1$Npm == 0) {
G1.logl <- (Ha1$Nc * log(1 - Ha1$p.hat))
G0.logl <- (Ha2$Npm * log(Ha2$p.hat)) + (Ha2$Nc * log(1 -
Ha2$p.hat))
contELRT <- 0
} else {
G1.logl <- (Ha1$Npm * log(Ha1$p.hat)) + (Ha1$Nc * log(1 -
Ha1$p.hat))
G0.logl <- (Ha2$Npm * log(Ha2$p.hat)) + (Ha2$Nc * log(1 -
Ha2$p.hat))
contELRT <- 0
}
}
else {
uniq1 <- length(unique(Group1[Group1 != 0]))
uniq2 <- length(unique(Group0[Group0 != 0]))
if ((uniq1 < 2) & (uniq2 < 2)) {
flag <- 0
if (Ho$Npm == 0) {
null.logl <- 0
G1.logl <- 0
G0.logl <- 0
contELRT <- 0
}
else {
null.logl <- (Ho$Npm * log(Ho$p.hat)) + (Ho$Nc * log(1 -
Ho$p.hat))
G1.logl <- (Ha1$Npm * log(Ha1$p.hat)) + (Ha1$Nc * log(1 -
Ha1$p.hat))
G0.logl <- (Ha2$Npm * log(Ha2$p.hat)) + (Ha2$Nc * log(1 -
Ha2$p.hat))
contELRT <- 0
}
}
else if (Ho$Npm == 0) {
flag <- 0
fit <- nlm(MeanELRT, p = c(0, BigMean), x = Ha1$cont,
y = Ha2$cont, hessian = FALSE, gradtol = 1e-15)
Lambda <- fit$estimate[1]
Mean <- fit$estimate[2]
SumWts <- GetWeights(fit, contX = Ha1$cont,
contY = Ha2$cont)
if (any(SumWts < 0.95)) contELRT <- NA
else contELRT <- fit$minimum
null.logl <- 0
G1.logl <- 0
G0.logl <- 0
}
else if (Ha1$Npm == 0) {
flag <- 1
fit <- nlm(MeanELRT, p = c(0, BigMean), x = Ha1$cont,
y = Ha2$cont, hessian = FALSE, gradtol = 1e-9)
Lambda <- fit$estimate[1]
Mean <- fit$estimate[2]
SumWts <- GetWeights(fit, contX = Ha1$cont, contY = Ha2$cont)
if (any(SumWts < 0.95)) contELRT <- NA
else contELRT <- fit$minimum
null.logl <- (Ho$Npm * log(Ho$p.hat)) + (Ho$Nc * log(1 -
Ho$p.hat))
G1.logl <- 0
G0.logl <- (Ha2$Npm * log(Ha2$p.hat)) + (Ha2$Nc * log(1 -
Ha2$p.hat))
}
else if (Ha2$Npm == 0) {
flag <- 1
fit <- nlm(MeanELRT, p = c(0, BigMean), x = Ha1$cont,
y = Ha2$cont, hessian = FALSE, gradtol = 1e-9)
Lambda <- fit$estimate[1]
Mean <- fit$estimate[2]
SumWts <- GetWeights(fit, contX = Ha1$cont,
contY = Ha2$cont)
if (any(SumWts < 0.95)) contELRT <- NA
else contELRT <- fit$minimum
null.logl <- (Ho$Npm * log(Ho$p.hat)) + (Ho$Nc * log(1 -
Ho$p.hat))
G1.logl <- (Ha1$Npm * log(Ha1$p.hat)) + (Ha1$Nc * log(1 -
Ha1$p.hat))
G0.logl <- 0
}
else {
flag <- 1
fit <- nlm(MeanELRT, p = c(0, BigMean,BigMean*2), x = Ha1$cont,
y = Ha2$cont, hessian = FALSE, gradtol = 1e-15,iterlim = 300)
Lambda <- fit$estimate[1]
Mean <- fit$estimate[2]
SumWts <- GetWeights(fit, contX = Ha1$cont, contY = Ha2$cont)
if (any(SumWts < 0.95)) {
contELRT <- NA
print(min(SumWts))
print(fit$code)
print(fit$estimate)
}
else {
contELRT <- fit$minimum
}
null.logl <- Ho$Npm * log(Ho$p.hat) + Ho$Nc * log(1 - Ho$p.hat)
G1.logl <- Ha1$Npm * log(Ha1$p.hat) + Ha1$Nc * log(1 - Ha1$p.hat)
G0.logl <- Ha2$Npm * log(Ha2$p.hat) + Ha2$Nc * log(1 - Ha2$p.hat)
}
}
logl <- G1.logl + G0.logl
X2 <- -2 * (null.logl - logl + contELRT)
if (flag == 0) {
pv <- 1 - pchisq(X2, 1)
q <- 1
} else {
pv <- 1 - pchisq(X2, 2)
q <- 2
}
N <- length(data)
Fpv <- 1 - pf(X2 * (N - q) / ((N - 1) * q), q, N - q)
ans <- list(statistic = X2, X2pvalue = pv, Fpvalue = Fpv)
return(ans)
}
log.star <- function(z, eps) {
ans <- z
lo <- (z < eps)
ans[lo] <- log(eps) - 1.5 + 2 * z[lo] / eps - 0.5 *
(z[lo] / eps)^2
ans[!lo] <- log(z[!lo])
ans
}
# Two sample ELRT for test of differences in means
MeanELRT <- function(params, x, y) {
Nx <- length(x)
Ny <- length(y)
Nt <- Nx + Ny
fx <- Nt / Nx
fy <- Nt / Ny
Zx <- 1 - fx * params[1] * (x - params[2])
Zy <- 1 + fy * params[1] * (y - params[2])
return(-sum(log.star(Zy, 1 / Nx)) - sum(log.star(Zx, 1 / Ny)))
}
source("R/trials/trial_loader.R")
test_ <- function(trial) {
x <- trial$Score
group <- trial$Group
# map group to 1 and 0
group <- as.numeric(group == "treatment")
return(ELRT(x, group))
}
p_value_type <- "Fpvalue" # "X2pvalue" # "Fpvalue"
trial_data <- load_equal_trials()
df <- trial_data$apply_to_each(test_, as.df = TRUE)
na_count_equal <- sum(is.na(df[[p_value_type]]))
p_values <- df[[p_value_type]][!is.na(df[[p_value_type]])]
p_value_rate_equal <- sum(p_values < 0.05) / length(p_values)
trial_data <- load_longer_trials()
df <- trial_data$apply_to_each(test_, as.df = TRUE)
na_count_longer <- sum(is.na(df[[p_value_type]]))
p_values <- df[[p_value_type]][!is.na(df[[p_value_type]])]
p_value_rate_longer <- sum(p_values < 0.05) / length(p_values)
trial_data <- load_shorter_trials()
df <- trial_data$apply_to_each(test_, as.df = TRUE)
na_count_shorter <- sum(is.na(df[[p_value_type]]))
p_values <- df[[p_value_type]][!is.na(df[[p_value_type]])]
p_value_rate_shorter <- sum(p_values < 0.05) / length(p_values)
print(paste0("used p_value_type:", p_value_type))
print(paste0("Type 1 Error:", p_value_rate_equal))
print(paste0("Power (Longer event durations):", p_value_rate_longer))
print(paste0("Power (Shorter event gap times):", p_value_rate_shorter))
print(paste0("NA count equal:", na_count_equal))
print(paste0("NA count longer:", na_count_longer))
print(paste0("NA count shorter:", na_count_shorter))
na_indices <- seq(df$X2pvalue)[is.na(df$X2pvalue)]
non_na_indices <- seq(df$X2pvalue)[!is.na(df$X2pvalue)]
na_indices[1]
na_trial <- trial_data$trials[[na_indices[3]]]
na_trials_max <- sapply(na_indices, function(index) var(trial_data$trials[[index]]$Score))
non_na_trials_max <- sapply(non_na_indices, function(index) var(trial_data$trials[[index]]$Score))
mean(na_trials_max)
mean(non_na_trials_max)
max(na_trial$Score)
max(non_na_trial$Score)
library(gamlss)
source("R/models/models.R")
source("R/trials/trial_loader.R")
x <- source("R/evaluation/distribution_fit/x.R")$value
trial_data <- load_longer_trials()
scenario_name <- trial_data$name
result_directory <- paste0("results/CDF/",scenario_name ,"/")
model <- ZERO_INFLATED_GAMMA() #LOG_ANOVA(c = 1)
install.packages("fitdistrplus")
library(ggplot2)
library(dplyr)
library(tidyr)
library(latex2exp)
source("R/model_computer.R")
source("R/helpers.R")
model_folder <- "results/shorter_gap_times"
model_files <- list.files(model_folder, full.names = TRUE)
# remove files with Tmp in it ...
df <- NULL
for (model_file in model_files) { # takes a while
scenario_factor <- get_prefixed_number(model_file, "_s_")
print(scenario_factor)
model_computer <- load_model_computer(model_file )
p_values <- get_value(model_computer,"p_value")
sig_p_values <- colMeans(p_values < 0.05, na.rm = TRUE)
print(sig_p_values)
for( model in names(sig_p_values) ){
df <- rbind(df, c(scenario_factor = scenario_factor, model = model , value = unname(sig_p_values[model])))
}
}
df <- data.frame(df)
df$value <- as.numeric(df$value)
df$scenario_factor <- as.numeric(df$scenario_factor)
df <- df[order(df$scenario_factor, decreasing = FALSE),]
# Convert the data to a long format suitable for plotting with ggplot
# levels <- unique(df$scenario_factor)
# base_level = level_index where level= 1
# base_level <- which(levels == 1)
# df$scenario_factor <- factor(df$scenario_factor, levels = levels)
# df$scenario_factor <- as.numeric(df$scenario_factor)
source("R/models/model_settings.R")
base_level <- 1.0
models <- sort(unique(df$model))
color_values <- unname(sapply(models , get_color))
labels <- unlist(lapply(models, function(x) TeX(map_labels(x))))
names(labels) <- models
lines_types <- setNames(1:length(models), models)
g <- ggplot(df, aes(x = scenario_factor, y = value, group = model)) +
geom_line(aes(color = model, linetype = model), size = 1.1) + # Map both color and linetype to model
labs(x = "Factor (Experimental/Control) for expected gap time between events", y = "Proportion of Significant P-values", title = "", color = "Model", linetype = "Model") +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5), legend.text = element_text(size = 15), legend.title = element_text(size = 0)) +
theme(axis.text = element_text(size = 14, face = "bold"), axis.title = element_text(size = 17, face = "bold")) +
theme(legend.key.width = unit(1, "cm")) +
ylim(0, 1) + scale_color_manual(values = color_values, labels =labels) + scale_linetype_manual(values = lines_types, labels = labels)
g
g <- g +
guides(fill = guide_legend(override.aes = list(size = 15))) +
geom_point(aes(color = model), size = 2.5, show.legend = FALSE) +
guides(color = guide_legend(nrow = 2, byrow = TRUE)) +
theme(legend.position = 'top') +
geom_vline(xintercept = base_level, linetype = "dotted", color = "black") +
annotate("text", x = base_level + 0.35, y = 0.92, label = "Equal expected \n gap time", angle = 0, color = "black", size = 5)
g
g <- g +
annotate("segment", x = 0.75, y = 0.05, xend = 0.12, yend = 0.05,
arrow = arrow(type = "closed", length = unit(0.02, "npc"))) +
annotate("text", x = 0.3, y = 0.075, label = "More frequent events in the experimental group", angle = 0, color = "black", size = 5)
g
levels <- unique(df$scenario_factor)
levels.r <- round(levels, 1)
levels <- ifelse(levels == levels.r, levels.r,levels)
#remove 0.8
levels <- levels[!levels %in% c(0.5,0.7,0.9)]
transfromation <- scales::trans_new("log_reverse",
transform = function(x) -log(x),
inverse = function(x) exp(-x))
g <- g + scale_x_continuous(trans=transfromation , breaks = levels , labels = levels )
g
ggsave("shorter_p_values.pdf", plot = g, width = 14, height = 7)
library(ggplot2)
library(dplyr)
library(tidyr)
library(latex2exp)
source("R/model_computer.R")
model_folder <- "results/longer_event_durations"
model_files <- list.files(model_folder, full.names = TRUE)
source("R/helpers.R")
df <- NULL
for (model_file in model_files) { # takes a while
scenario_factor <- get_prefixed_number(model_file, "_l_")
print(scenario_factor)
model_computer <- load_model_computer(model_file )
p_values <- get_value(model_computer,"p_value")
sig_p_values <- colMeans(p_values < 0.05, na.rm = TRUE)
print(sig_p_values)
for( model in names(sig_p_values) ){
df <- rbind(df, c(scenario_factor = scenario_factor, model = model , value = unname(sig_p_values[model])))
}
}
df <- data.frame(df)
df$value <- as.numeric(df$value)
df$scenario_factor <- as.numeric(df$scenario_factor)
df <- df[order(df$scenario_factor, decreasing = FALSE),]
# Convert the data to a long format suitable for plotting with ggplot
# levels <- unique(df$scenario_factor)
# base_level = level_index where level= 1
# base_level <- which(levels == 1)
# df$scenario_factor <- factor(df$scenario_factor, levels = levels)
# df$scenario_factor <- as.numeric(df$scenario_factor)
source("R/models/model_settings.R")
base_level <- 1.0
models <- sort(unique(df$model))
color_values <- unname(sapply(models , get_color))
labels <- unlist(lapply(models, function(x) TeX(map_labels(x))))
names(labels) <- models
lines_types <- setNames(1:length(models), models)
g <- ggplot(df, aes(x = scenario_factor, y = value, group = model)) +
geom_line(aes(color = model, linetype = model), size = 1.1) + # Map both color and linetype to model
labs(x = "Factor (Experimental/Control) for expected gap time between events", y = "Proportion of Significant P-values", title = "", color = "Model", linetype = "Model") +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5), legend.text = element_text(size = 15), legend.title = element_text(size = 0)) +
theme(axis.text = element_text(size = 14, face = "bold"), axis.title = element_text(size = 17, face = "bold")) +
theme(legend.key.width = unit(1, "cm")) +
ylim(0, 1) + scale_color_manual(values = color_values, labels =labels) + scale_linetype_manual(values = lines_types, labels = labels)
g
g <- g+  guides(fill = guide_legend(override.aes = list(size = 15))) +
geom_point(aes(color = model), size = 2.5, show.legend = FALSE) +
guides(color = guide_legend(nrow = 2, byrow = TRUE)) +
theme(legend.position = 'top') +
geom_vline(xintercept = base_level, linetype = "dotted", color = "black") +
annotate("text", x = base_level + 1, y = 0.92, label = "Equal expected \n even duration", angle = 0, color = "black", size = 5)
g <- g +
annotate("segment", x = 2, y = 0.03, xend = 2 + 3.4, yend = 0.03, ,
arrow = arrow(type = "closed", length = unit(0.02, "npc"))) +
annotate("text", x = 3.5, y = 0.06, label = "Longer event durations in the experimental group", angle = 0, color = "black", size = 4)
g
#ggsave("longer_p_values.pdf", plot = g, width = 10, height = 5)
data <- c(1,2,3,4,5)
lm(log(data))
lm(log(data)~ 1)
fitdist(data, "lnorm")
fitdistr(data, "lnorm")
library(fitdistrplus)
data <- c(1,2,3,4,5)
lm(log(data)~ 1)
fitdistr(data, "lnorm")
library(fitdistrplus)
data <- c(1,2,3,4,5)
lm(log(data)~ 1)
fitdistr(data, "lnorm")
data <- c(1,2,3,4,5)
lm(log(data)~ 1)
fitdist(data, "lnorm")
fitdist(log(data), "norm")
summary(lm(log(data)~ 1))
fitdist(data, "lnorm")
fitdist(log(data), "norm")
data <- abs(rnorm(100,10,5))
summary(lm(log(data)~ 1))
fitdist(data, "lnorm")
fitdist(log(data), "norm")
data <- abs(rnorm(1000,10,5))
summary(lm(log(data)~ 1))
fitdist(data, "lnorm")
fitdist(log(data), "norm")
data <- abs(rnorm(10,10,5))
summary(lm(log(data)~ 1))
fitdist(data, "lnorm")
fitdist(log(data), "norm")
summary(lm.model <- lm(log(data)~ 1))
AIC(lm.model)
lm.model
summary(lm.model <- lm(log(data)~ 1))
AIC(lm.model)/2-1
fitdist(data, "lnorm")$loglike
fitdist(data, "lnorm")$loglikelihood
lnorm <-fitdist(data, "lnorm")
lnorm$loglik
log_fitdsit <- fitdist(log(data), "norm")
log_fitdsit$loglik
AIC(lm.model)/2-2
lnorm$loglik - sum(log(data))
lnorm$loglik + sum(log(data))
?glm
glm(log(data)~ 1)
summary(glm(log(data)~ 1))
?fitdist
fitdist(log(data), "norm",method = "mle")
fitdist(log(data), "norm",method = "mse")
log_fitdsit <- fitdist(log(data), "norm",method = "mse")
log_fitdsit$loglik
log_fitdsit <- fitdist(log(data), "norm",method = "mse")
log_fitdsit$loglik
lnorm <-fitdist(data, "lnorm")
lnorm$loglik
lnorm$loglik + sum(log(data))
lnorm <-fitdist(data, "lnorm")
lnorm$loglik
log_fitdsit <- fitdist(log(data), "norm")
log_fitdsit$loglik
fitdist(log(data), "norm",method = "mse")
log_fitdsit <- fitdist(log(data), "norm",method = "mse")
log_fitdsit$loglik
fitdist(data, "norm",method = "mse")
fitdist(data, "norm",method = "mle")
fitdist(data, "norm",method = "mme")
p_observing_0 <- 0.3056
p_more_than_half_0 <- pbinom(9 , 100, p_observing_0 , lower.tail = FALSE )
p_more_than_half_0
p_observing_0 <- 0.3056
p_more_than_half_0 <- pbinom(9 , 20, p_observing_0 , lower.tail = FALSE )
p_more_than_half_0
p_observing_0 <- 0.3056
p_more_than_half_0 <- pbinom(10 , 20, p_observing_0 , lower.tail = FALSE )
p_more_than_half_0
p_observing_0 <- 0.3056
p_more_than_half_0 <- pbinom(10 , 20, p_observing_0 , lower.tail = TRUE )
p_more_than_half_0
p_observing_0 <- 0.3056
p_more_than_half_0 <- pbinom(10 , 20, p_observing_0 , lower.tail = FALSE )
p_more_than_half_0
p_observing_0 <- 0.3056
p_more_than_half_0 <- pbinom(9 , 20, p_observing_0 , lower.tail = TRUE )
p_more_than_half_0
